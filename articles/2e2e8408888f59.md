---
title: "（今さら）Gemini API使ってみる"
emoji: "🧞‍♂️"
type: "tech"
topics:
  - "langchain"
  - "生成ai"
  - "gemini"
published: true
published_at: "2024-02-15 21:01"
---

## 初めに
Gemini APIが使えるようになってから2ヶ月くらい経ってしまいましたが、2024年2月12日現在で、まだ無料で使えるようなので今のうちに触っておこうという記事です！
:::message
今回の記事は本当に初歩的な内容で、公式のドキュメントを基に触ってみた程度の情報量となっています。
:::

## Geminiとは
まず読み方ですが、Geminiは日本だと「ジェミニ」と呼ばれることが現状多いです。GeminiはGoogleが作った生成AIのモデルです。OpenAIが提供しているGPTとざっくり同じ類のものだと思ってもらえればOKです。Geminiがどういうものなのかは調べるとわかりやすい記事がたくさん出てくるはずです！
↓一応１記事参考に貼っときます。
https://www.goatman.co.jp/media/google-gemini-bard/

:::message
Geminiはモデルの名前でしたが、Googleが提供していたAIチャットアプリのBardの名前もGeminiに変更されましたね。
参照：https://japan.googleblog.com/2024/02/bard-gemini-ultra-10-gemini.html
:::

## Google AI Studio
まず、開発に関わる人でない人でchatGPTのようにAIとチャットしたいだけの人であれば、以下リンクから簡単にチャットが利用できます（Googleログインは必要かも）。これがGeminiのアプリ（旧Bard）のことになります。
https://gemini.google.com/app

開発に関わる人で、Geminiを使いたい人は以下リンクのGoogle AI Studioを使ってみましょう。
[Google AI Studio](https://makersuite.google.com/app/prompts/new_freeform)
このGoogle AI Studioでは気軽にAIにチャットで回答してもらえることに加え、設定を変えて質問をしたり、いろんなことができるようになってます。自分もサラッと触ったくらいですが、ざっくり以下のことができるとわかりました。
- チャットで気軽にAIの回答が確認できる
- 設定を色々変更できる
    - モデル（Gemini Pro、Gemini Pro Vision）
    - temperature（回答のランダム性）
    - Add stop sequence（指定した文字が入ると回答を止める）
    - その他
- 実装するコードを参考として表示してくれる（図1）
- APIの使い方など、開発の参考になるドキュメントへのリンクもある
- APIキーの作成
→クレジットカードの登録などもなしに簡単に作成できてしまったので、いいのかな？と思ってしまいました。
![](https://storage.googleapis.com/zenn-user-upload/90447db4f399-20240212.png =500x)
*図1*


:::message
直感的に使えるUIになっていますが、できることなどをもっと知りたい人は、以下リンクのドキュメントを確認してください。
https://ai.google.dev/tutorials/ai-studio_quickstart?hl=ja
:::

## Gemini APIの一番基本の使い方
では、実際にGeminiをAPIから使用してみましょう。今回はpythonを用いますが、他の言語での使用方法も公式のドキュメントが色々あります。今後、pythonの環境構築は完了している前提で話を進めていきます。

### APIキーの取得
先ほどのGoogle AI Studioの画面からAPIキーを取得できます。
![](https://storage.googleapis.com/zenn-user-upload/5c6591748ca6-20240213.png =500x)
*図2*
上図は1つAPIキーを作成した後の画面ですが、「Create API key」から簡単にAPIキーを作成することができました。その際、クレジットの登録などは必要なかったため、こんなに簡単に使えていいの？という感じでした。

:::message
以下リンクにAPIキーに関するドキュメントもあります。
https://ai.google.dev/tutorials/setup?hl=ja
:::

### Gemini APIを叩く
基本は以下のクイックスタートのドキュメントを見て進めれば良いと思います。
https://ai.google.dev/tutorials/python_quickstart
正直ドキュメントを読めば十分と言えますが、今回はGemini APIをpythonで呼び出すまでを丁寧に書いてみます。
1. 必要なライブラリをインストール
   適宜venvなどの仮想環境に入った後、以下コマンドをシェルで実行。
   ```
   pip install google-generativeai python-dotenv
   ```
   →なお、python-dotenvは私が.envファイルで環境変数をセットしたいためインストールしたもので必須ではありません。
3. コード作成
   .envファイルにAPIキーの値を「GOOGLE_API_KEY」として記載。
   main.pyに以下のコードを記載。
   ```python:main.py
    import os
    from dotenv import load_dotenv
    import google.generativeai as genai
    
    # .envファイルの読み込み
    load_dotenv()
    
    # API-KEYの設定
    GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')
    genai.configure(api_key=GOOGLE_API_KEY)
    
    gemini_pro = genai.GenerativeModel("gemini-pro")
    prompt = "こんにちは"
    response = gemini_pro.generate_content(prompt)
    print(response.text)
   ```
   modelとしてはGemini Proを利用するコードになっています。
   promptの"こんにちは"の部分が質問内容になっているのでここは自由に変えてもらってOKです。
4. コードの実行
   以下コマンドをシェルで実行すると回答が返ってきます。
   ```
   python main.py
   ```

## Langchainを使って、GeminiのStreamlitチャットアプリの実装
次は、GeminiAPI、Langchain、Streamlitを用いて一瞬でチャットアプリを作ります。先ほどとの違いはLangchainを使うっていうことと、Streamlitを用いてチャットアプリにするので先ほどのコンソールへの回答の表示に比べて、見た目が良くなるといった感じです。
:::message
先にネタバレなのですが、継続して会話をできるようにしたかったのですが、Langchain&Geminiで継続会話をする方法について、公式ドキュメント（Langchain）やネットの記事などで見つけられず、単発での質問のみになっています。LangchainとGeminiはまだ継続会話できないのかな？とも思ったのですが、詳しい情報持ってる方いれば教えていただけると嬉しいです。
:::

以下コマンドでライブラリをインストールします。
```
pip install python-dotenv streamlit langchain-google-genai 
```
今回はlangchainを用いてGeminiAPIを呼び出すので先ほどとGeminiに関するライブラリも変わっています。langchainはアップデートの速度が速いので私がインストールしたバージョンを一応記載しておきます。
```
langchain-google-genai==0.0.8
```
以下が出来上がったコードになります。
```python:app.py
import os
from dotenv import load_dotenv
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI

load_dotenv()
# モデルはGemini Proを使用
llm = ChatGoogleGenerativeAI(model='gemini-pro')

st.title("langchain-streamlit-app")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

prompt = st.chat_input("What is up?")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        response = llm.invoke(prompt)
        st.markdown(response.content)

    st.session_state.messages.append({"role": "assistant", "content": response.content})
```

Geminiに関するところは以下の部分で、あとはほとんどStreamlitに関する記述になります。見ればなんとなくモデル選択して、入力した内容で質問投げているんだなということがわかると思います。
```python
llm = ChatGoogleGenerativeAI(model='gemini-pro')
# 省略
prompt = st.chat_input("What is up?")
# 省略
response = llm.invoke(prompt)
```

あとは、以下コマンドでStreamlitを起動するだけです。
```
streamlit run app.py   
```
アプリの画面は下図のようになり、「What is up?」と書いてある部分に質問を入力して送信することで回答してくれます。赤色の人間マークが自分の質問内容、黄色のロボットマークがAIからの回答になります。それなりにちゃんと回答してくれていることがわかります。
![](https://storage.googleapis.com/zenn-user-upload/cd073665682e-20240215.png =500x)
*図3*

継続会話ができるような実装にはなってないので、下図のように当然前の質問内容を踏まえた回答はしてくれません。
![](https://storage.googleapis.com/zenn-user-upload/09b63a7f60f4-20240215.png =500x)
*図4*

## GeminiAPIで継続会話ができるコンソールアプリの実装
Langchainを使用しないGeminiAPIで継続会話ができる機能もあるみたいなので使ってみます。
使い方についての詳細は以下をご確認ください。
https://ai.google.dev/tutorials/python_quickstart#chat_conversations

継続会話ができるコンソールアプリの完成版を以下に記載します。
```python
import os
from dotenv import load_dotenv
import google.generativeai as genai

# .envファイルの読み込み
load_dotenv()

# API-KEYの設定
GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

model = genai.GenerativeModel("gemini-pro")
# チャット履歴を初期化
chat = model.start_chat(history=[])

print("チャットボットです。何か質問はありますか？（終了するには「終了」と入力してください）")

while True:
    # ユーザーからの入力を受け取る
    user_input = input("質問内容を入力してください: ")

    # 終了条件
    if user_input == "終了":
        print("チャットを終了します。またのお越しを！")
        break
    
    # チャットの応答
    response = chat.send_message(user_input)
    print(response.text)
```
今までと大きくは変わりませんが、変わるところは以下でチャット履歴機能が使えるようになり、
```python
# チャット履歴を初期化
chat = model.start_chat(history=[])
```
以下コードの実行でGeminiAPIに質問を投げつつ、その情報を履歴として保持して回答してくれるということです。
```python
response = chat.send_message(user_input)
```
下図は実際のコンソール画面です。ちゃんと過去の質問内容を覚えてくれています。
![](https://storage.googleapis.com/zenn-user-upload/3a16edc295e9-20240215.png)
*図5*


## 最後に
今回は本当に簡単なことしかやっていませんが、Gemini API自体はとても簡単に使えるということがわかりました。ただ、継続会話の部分など、意外と情報が見つからなくて悩んでしまいました（OpenAIだとLangchainを使う場合でも情報がたくさんあり、もっと楽でした）。今回できなかったことも含め徐々に難易度を上げて色々試してみたいと思っています！

## 参考文献
https://gihyo.jp/book/2023/978-4-297-13839-4